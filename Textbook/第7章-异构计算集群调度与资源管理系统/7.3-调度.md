<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/YanjieGao/AI-System/blob/main/LICENSE)版权许可-->

# 7.3 调度（Scheduling）

在之前的章节，我们已经介绍集群管理中的运行时，但是作业在启动前，需要平台本身进行决策进而进行调度。本章将围绕经典平台调度算法进行介绍，期望让读者了解作业调度的经典问题和算法。

- [7.3 调度（Scheduling）](#73-调度scheduling)
  - [7.3.1 调度问题优化目标](#731-调度问题优化目标)
  - [7.3.2 群调度](#732-群调度)
  - [7.3.3 DRF调度](#733-drf调度)
  - [7.3.4 容量调度](#734-容量调度)
  - [7.3.5 虚拟集群](#735-虚拟集群)
  - [7.3.6 抢占式调度](#736-抢占式调度)
  - [7.3.7 深度学习调度算法实验与模拟研究](#737-深度学习调度算法实验与模拟研究)
    - [7.3.7.1 数据读取](#7371-数据读取)
    - [7.3.7.2 评测指标设定](#7372-评测指标设定)
    - [7.3.7.3 算法实现与评测](#7373-算法实现与评测)
  - [参考文献](#参考文献)


## 7.3.1 调度问题优化目标

针对一批作业调度，常常考虑以下指标 :

- 吞吐(Throughput)：单位时间能完成的作业数量。平台希望吞吐量越大越好。 
- 完工时间(Makespan)：作业从启动到终止的时间，希望其越小越好，有些调度算法也考虑所有作业的整体完工时间作为优化目标。
- 平均响应时间(Average Response Time):平均响应时间是请求者在授予对全局资源的请求之前必须等待的平均时间。平台希望平均响应时间越短越好。
- 公平性(Fairness)：资源使用在平台用户或组之间平均分配，而不是在作业之间平均分配。
- 资源利用率(Utilization) ：描述用于作业的资源占总资源的百分比。平台希望利用率越高越好。
- 服务水平协议(SLA)：服务级别协议 (SLA-service-level agreement) 是服务提供商和客户之间的承诺。例如：服务的特定方面——质量、可用性、责任——在服务提供商和服务用户之间达成一致。 

接下来，我们将通过经典的调度算法，看平台常用算法是如何解决遇到的问题的。

## 7.3.2 群调度

调度并行或分布式作业会常常遇到哪些问题?

- 问题：并行作业可以同时执行多个任务，如果有依赖任务没启动，已启动任务会在同步点忙于等待或者频繁上下文切换 (如右图)：
  - 无法训练：等待不能启动的任务
  - 资源浪费：已启动的任务造成资源浪费
- 深度学习训练特点：
  - 深度学习作业任务需要同步梯度
  - GPU软件栈无法支持任务上下文切换


<center> <img src="./img/3/7-3-2-gangscheduleproblem.png" ch="500" width="400" height="400" /></center>
<center>图7-3-1. 并行执行作业可能产生的问题</center>

群调度(Gang Scheduling) Wiki定义：
一种用于并行系统的调度算法，用于调度相关线程或进程在不同处理器上同时运行。 

策略：
使用群调度(Gang Scheduling)同时启动深度学习任务进程。

<center> <img src="./img/3/7-3-3-gangschedule.png" ch="500" width="400" height="300" /></center>
<center>图7-3-2. 并行执行作业可能产生的问题</center>


## 7.3.3 DRF调度 

异构资源如何公平(Fairness)调度?
- 问题：包含异构资源类型的系统中如何进行多作业公平(Fairness)的资源调度？
- 挑战：相比传统单资源公平调度，深度学习作业也需要使用多种异构资源 (CPU, Host memory, etc.)，并且需要调度GPU及GPU memory
设计目标：吞吐(Throughput)与公平(Fairness)

Dominant Resource Fairness (DRF)

- 优化目标：
DRF 尝试最大化系统中的最小主导份额(smallest dominant share)

- 策略：
通过同类型资源在集群整体资源中的份额确定主导资源 (dominant resource) 
基于最大最小公平（max-min fairness）的针对多资源类型（e.g. GPU, CPU）的调度算法


<center> <img src="./img/3/7-3-1-drf.png" ch="500" width="300" height="400" /></center>
<center>图7-3-3. 2个作业的DRF调度实例</center>


$$Cluster \  Resources: [10 \  GPU, 20GB \ RAM] $$

$$
Job \ 1: \\
Total \ GPU \ 1+1 = 2 \ GPU \\
GPU \ Share \ 2/10 = 0.2 \\
Total \ Memory \ 4+4 = 8GB \\
Memory \ Share \ 8/20 = 0.4 \\
SHARE = 0.4 \ [Dominant \ resource \ is \ Memory]
$$

$$
Job \ 2:  \\
Total \ GPU \ 2+3 = 5 \ GPU \\
GPU \ Share \ 5/10 = 0.5 \\
Total \ Memory \ 2+2 = 4GB \\
Memory \ Share \ 4/20 = 0.2 \\
SHARE = 0.5 [Dominant resource is GPU]
$$


## 7.3.4 容量调度

如何让多个小组共享集群？
- 问题：
  - 能否为多个组织共享集群资源？
  - 共享集群资源的同时，如何同时为每个组织提供最小容量保证?
  - 空闲资源能否弹性为其他组织利用？
- 挑战：相比传统容量调度调度，深度学习作业也需要考虑调度GPU及GPU memory
- 设计目标：Utilization, Fairness and SLA


<center> <img src="./img/3/7-3-4-capaproblem.png" ch="500" width="400" height="400" /></center>
<center>图7-3-4. 资源占用过多造成其他组无法分配资源问题</center>

目的：
  - 支持多租(Multi-tenant）资源共享
策略：
- Utilization: 
  - 虚拟集群 (Virtual Cluster）
  - Bonus Resource
- Fairness:
  - Dominant Resource Fairness (DRF)
  - User Limit Factor：控制单用户的可以消耗的最大资源
- SLA 
  - 抢占(Preemption)

<center> <img src="./img/3/7-3-5-capascheduling.png" ch="500" width="400" height="300" /></center>
<center>图7-3-5. 容量调度</center>

## 7.3.5 虚拟集群

虚拟集群 (Virtual Cluster) 映射
- 虚拟集群根据小组的配额进行定义
- 将虚拟集群映射到物理集群

<center> <img src="./img/3/7-3-6-vc-bind.png" ch="500" width="400" height="300" /></center>
<center>图7-3-6. 虚拟集群和物理集群映射与绑定</center>

目的：提升资源利用率
策略：
- 虚拟集群根据小组的配额进行定义
- 将虚拟集群映射到物理集群
- 资源被分配给租户(Tenants)
- 每个Tenant构成了一个虚拟集群(VC)

<center> <img src="./img/3/7-3-7-vc-define.png" ch="500" width="400" height="400" /></center>
<center>图7-3-6. 虚拟集群资源分配</center>

## 7.3.6 抢占式调度

如何让调度兼顾SLA？

- 问题：
共享集群资源被其他组织占用提升了资源利用率但是无法保证SLA?
- 挑战：
在深度学习作业下，被抢占的作业当前只能失败，无法像传统OS上下文切换
- 设计目标：
兼顾有限资源利用和服务等级协议（SLA）

<center> <img src="./img/3/7-3-8-preemptive.png" ch="500" width="400" height="400" /></center>
<center>图7-3-7. 作业等待时间过长问题</center>

<center> <img src="./img/3/7-3-9-preemptive.png" ch="500" width="400" height="400" /></center>
<center>图7-3-8. 抢占调度</center>


## 7.3.7 深度学习调度算法实验与模拟研究

此存储库[philly-traces](https://github.com/msr-fiddle/philly-traces) 包含 Microsoft 内部 Philly集群上第一方 (first-party) DNN 训练工作负载的代表性子集。 数据是 ATC’19 中“Analysis of large-scale multi-tenant GPU clusters for DNN training workloads”中描述的工作负载的一个脱敏数据子集。 这项工作是作为 Microsoft Research 的 Project Fiddle 的一部分完成的。

### 7.3.7.1 数据读取
读者可以参考库中提供的脚本读取数据并了解数据模式。
### 7.3.7.2 评测指标设定
读者可以根据本章开始介绍的指标设计优化目标。
### 7.3.7.3 算法实现与评测
读者可以选用以上介绍的经典算法作为基准测试，设计新的算法，并通过真实平台数据模拟，看能否提升当前目标，超越基准算法，并进行结果分析，形成分析报告或论文。

## 参考文献

- [Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training Workloads](https://dl.acm.org/doi/10.5555/3358807.3358888)
- Multi-tenant GPU Clusters for Deep LearningWorkloads: Analysis and Implications
- Gandiva: Introspective Cluster Scheduling  for Deep Learning
- Dominant Resource Fairness: Fair Allocation of Multiple Resource Types 
- All You Need to Know about Scheduling Deep Learning Jobs 
- https://github.com/microsoft/pai
- https://www.kubeflow.org/ 
- Kubeflow Pipelines With GPUs
- YARN – The Capacity Scheduler
- Better SLAs via Resource-preemption in YARN’s Capacity Scheduler
- Kube-Batch: Dominant Resource Fairness (DRF)

