<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/YanjieGao/AI-System/blob/main/LICENSE)版权许可-->

- [7.1 异构计算集群管理系统简介](#71-异构计算集群管理系统简介)
  - [7.1.1 多租环境运行的训练作业](#711-多租环境运行的训练作业)
  - [7.1.2 作业生命周期](#712-作业生命周期)
  - [7.1.3 资源管理系统的设计目标](#713-资源管理系统的设计目标)
  - [7.2 训练作业，镜像与容器](#72-训练作业镜像与容器)
  - [7.2.1 深度学习作业依赖于规格](#721-深度学习作业依赖于规格)
  - [7.2.2 环境依赖：镜像](#722-环境依赖镜像)
  - [7.2.3 运行时资源隔离：容器](#723-运行时资源隔离容器)

# 7.1 异构计算集群管理系统简介

## 7.1.1 多租环境运行的训练作业


<img src="./img/1/7-1-1-jobsubmission.png" ch="500" />

<center>图7-1-1. 多租环境提交运行作业</center>

多用户共享多GPU服务器

- 多作业(Job)，多用户
- 作业环境需求多样
- 作业资源需求多样
- 服务器软件环境单一
- 服务器空闲资源多样

调度与资源管理系统重要性

- 提供人工智能基础架构支持
  - 深度学习作业(Job)调度(Scheduling)与管理
  - 异构硬件管理  
- 提升生产力
  - 用户专注于模型创新，无需关注系统部署，管理
  - 模型，代码和数据共享，加速研究与创新


## 7.1.2 作业生命周期



<img src="./img/1/7-1-2-cluster.png" ch="500" />
<center>图7-1-2. GPU集群</center>

作业生命周期

1. 作业提交与排队
2. 作业资源分配与调度
3. 作业执行完成与释放

集群环境的新问题

1. 如何提交作业与解决环境依赖问题？
2. 如何高效调度作业并分配资源？
3. 如何将启动的作业运行时资源与命名空间隔离？ 


## 7.1.3 资源管理系统的设计目标

## 7.2 训练作业，镜像与容器
## 7.2.1 深度学习作业依赖于规格
## 7.2.2 环境依赖：镜像

Dockerfile实例

```dockerfile
FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04
ARG PYTHON_VERSION=3.6
…
RUN apt-get update && apt-get install -y --no-install-recommends \
…
RUN curl -o ~/miniconda.sh 
…
 /opt/conda/bin/conda install -y -c pytorch magma-cuda100 && \
…
WORKDIR /opt/pytorch
COPY . .
…
WORKDIR /workspace
RUN chmod -R a+w .

```
## 7.2.3 运行时资源隔离：容器
