<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/YanjieGao/AI-System/blob/main/LICENSE)版权许可-->

- [7.2训练作业，镜像与容器](#72训练作业镜像与容器)
  - [7.2.1 深度学习作业](#721-深度学习作业)
  - [7.2.2 环境依赖：镜像](#722-环境依赖镜像)
  - [7.2.3 运行时资源隔离：容器](#723-运行时资源隔离容器)
  - [参考文献](#参考文献)

本章将围绕平台的运行时总结

# 7.2训练作业，镜像与容器

## 7.2.1 深度学习作业

当深度学习开发者在本地机器或者独占服务器进行模型的开发与训练时，环境问题较少，还没有暴露更多问题和挑战。例如请大家思考下面列出的几点因素：

- 独占环境，无需考虑环境，资源隔离问题。
- 环境依赖路径: 本地/anaconda3。
  - 用户通过Python层的包管理软件或环境变量配置路径，即可完成Python库这层的依赖软件的隔离。
- GPU环境依赖: 本地/usr/local/cuda。
  - 用户本地NVIDIA CUDA等底层库较为固定，也可以通过环境变量较为方便的进行切换。
- 数据路径: 本地/data
  - 用户数据直接上传到服务器本地磁盘，带宽较高。
- 直接执行启动脚本: 存储在服务器磁盘，修改，调试监控等较为方便。

```
python train.py --batch_size=256  --model_name=resnet50
```


<img src="img/2/7-2-2-submit.png" ch="300" />
<center>图7-2-1. 4块GPU的服务器</center>



当深度学习作业准备提交到平台，用户需要提供什么信息呢？我们可以参考以下实例为例，实例来源于[OpenPAI](https://github.com/microsoft/pai)的提交作业样本模板。

```
{
    "jobName": "restnet",
    "image": "example.tensorflow:stable",
    "dataDir": "/tmp/data",
    "outputDir": "/tmp/output",
    ...
    "taskRoles": [
        {
            ...
            "taskNumber": 1,
            "cpuNumber": 8,
            "memoryMB": 32768,
            "gpuNumber": 1,
            "command": "python train.py --batch_size=256 \ 
		--model_name=resnet50"
        }
    ]
}
```

从作业提交模板中我们主要关注几个方面，并思考平台需要提供怎样的支持。

- 环境依赖：
  - 问题：平台集群中的机器都是相同的操作系统与环境，如何支持用户使用不同的深度学习框架（例如，TensorFlow和PyTorch）和版本？
  - 解决方法：通过"image"填写的Docker镜像名，解决环境依赖问题。用户需要提前将打包好的依赖构建为Docker镜像，并提交到指定的镜像中心，供作业下载。 
- 数据与代码：
  - 问题：平台上一般运行的是深度学习训练作业，每个作业都需要一定的数据作为输入，同时执行相应的代码，如果将数据和代码直接上传会造成接受用户请求的服务器负载过大，同时不能复用已经上传的数据和代码。
  - 解决方法：通过"dataDir"和"outputDir"填写作业依赖的数据和输出路径。用户上传数据和代码到平台指定的文件系统中的相应路径下，未来平台将数据和代码挂载到相应的作业进程。
- 资源申请量：
  - 问题：用户可能会提交运行使用单GPU的作业，多块GPU的作业和分布式的作业，面对多样的用户需求，平台需要用户明确告知，否则容易提供过多资源浪费，或过少资源造成作业无法启动。
  - 解决方法：用户明确声明需要使用的计算资源（例如，GPU和CPU）和内存，这样让平台根据指定调度策略将匹配的空闲资源进行分配。
- 资源隔离：
  - 问题：用户作业被分配指定资源后，可能多个作业在一台服务器执行，如何保证作业之间尽量不互相干扰？
  - 解决方法：平台可以通过[容器](https://www.docker.com/resources/what-container)/[cgroup](https://en.wikipedia.org/wiki/Cgroups)技术，将进程进行资源限定和隔离。
- 任务部署模式：
  - 问题：对于分布式的作业，如果用户不说明，平台无法知道并行化的策略，进而无法确认需要启动的任务数量。需要用户显式的声明。
  - 解决方法：对于分布式的作业，用户要明确告知需要启动的任务数量，进而平台能够启动多个任务副本进行训练。
- 作业启动命令：
  - 问题：当平台给作业分配资源，需要用户告知作业的启动命令，进而执行相应的代码。
  - 解决方法：用户需要明确在作业中描述相应的代码启动入口命令，进而让作业代码能够启动并执行。

通过以上问题描述和解决方法，相信您已经了解在平台中执行的作业和本地执行的作业差异和需要考虑的问题，我们将在后面章节的内容中，逐步展开其中的重要技术点和原理。

## 7.2.2 环境依赖：镜像
## 7.2.3 运行时资源隔离：容器

Dockerfile实例

```dockerfile
FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04
ARG PYTHON_VERSION=3.6
…
RUN apt-get update && apt-get install -y --no-install-recommends \
…
RUN curl -o ~/miniconda.sh 
…
 /opt/conda/bin/conda install -y -c pytorch magma-cuda100 && \
…
WORKDIR /opt/pytorch
COPY . .
…
WORKDIR /workspace
RUN chmod -R a+w .

```

## 参考文献 

- https://man7.org/linux/man-pages/man7/cgroups.7.html
- https://man7.org/linux/man-pages/man7/namespaces.7.html
- https://www.docker.com/
- https://docs.docker.com/engine/reference/commandline/image/
- https://hub.docker.com/
- https://www.docker.com/resources/what-container
- https://github.com/NVIDIA/nvidia-docker 
- Use the AUFS storage driver
- Making Containers More Isolated: An Overview of Sandboxed Container Technologies
- Jörg Thalheim, Pramod Bhatotia, Pedro Fonseca, and Baris Kasikci. 2018. CNTR: lightweight OS containers. In Proceedings of the 2018 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC '18). USENIX Association, USA, 199–212.
- Edward Oakes, Leon Yang, Dennis Zhou, Kevin Houck, Tyler Harter, Andrea C. Arpaci-Dusseau, and Remzi H. Arpaci-Dusseau. 2018. SOCK: rapid task provisioning with serverless-optimized containers. In Proceedings of the 2018 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC '18). USENIX Association, USA, 57–69.
- https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf
- https://www.nvidia.com/en-us/technologies/multi-instance-gpu/
- http://www.rcuda.net/