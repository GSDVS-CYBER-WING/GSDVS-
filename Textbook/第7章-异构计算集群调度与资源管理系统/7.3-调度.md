<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/YanjieGao/AI-System/blob/main/LICENSE)版权许可-->

# 7.3 调度（Scheduling）

在之前的章节，我们已经介绍集群管理中的运行时，但是作业在启动前，需要平台本身进行决策进而进行调度。本章将围绕经典平台调度算法进行介绍，期望让读者了解作业调度的经典问题和算法。

- [7.3 调度（Scheduling）](#73-调度scheduling)
  - [7.3.1 调度问题优化目标](#731-调度问题优化目标)
  - [7.3.2 群调度](#732-群调度)
  - [7.3.3 DRF调度](#733-drf调度)
  - [7.3.4 容量调度](#734-容量调度)
  - [7.3.5 虚拟集群](#735-虚拟集群)
  - [7.3.6 抢占式调度](#736-抢占式调度)
  - [7.3.7 实验模拟](#737-实验模拟)
    - [7.3.7.1 数据读取](#7371-数据读取)
    - [7.3.7.2 评测指标设定](#7372-评测指标设定)
    - [7.3.7.3 算法实现与评测](#7373-算法实现与评测)
  - [参考文献](#参考文献)


## 7.3.1 调度问题优化目标

针对一批作业调度，常常考虑以下指标 :

- 吞吐(Throughput) 
- 完工时间(Makespan) 
- 平均响应时间(Average Response Time）
- 公平性(Fairness)
- 资源利用率(Utilization) 
- 服务水平协议 (SLA)

调度并行或分布式作业会有哪些问题?

- 问题：并行作业可以同时执行多个任务，如果有依赖任务没启动，已启动任务会在同步点忙于等待或者频繁上下文切换 (如右图)：
  - 无法训练：等待不能启动的任务
  - 资源浪费：已启动的任务造成资源浪费
- 深度学习训练特点：
  - 深度学习作业任务需要同步梯度
  - GPU软件栈无法支持任务上下文切换
- 目标：High Throughput, High Utilization and Short Response Times 



## 7.3.2 群调度

Wiki定义：
A scheduling algorithm for parallel systems that schedules related threads or processes to run simultaneously on different processors. 
策略：
同时启动深度学习任务进程

## 7.3.3 DRF调度 

异构资源如何公平(Fairness)调度?
- 问题：包含异构资源类型的系统中如何进行多作业公平(Fairness)的资源调度？
- 挑战：相比传统单资源公平调度，深度学习作业也需要使用多种异构资源 (CPU, Host memory, etc.)，并且需要调度GPU及GPU memory
设计目标：吞吐(Throughput)与公平(Fairness)

Dominant Resource Fairness (DRF)

- 优化目标：
DRF 尝试最大化系统中的最小主导份额(smallest dominant share)

- 策略：
通过同类型资源在集群整体资源中的份额确定主导资源 (dominant resource) 
基于最大最小公平（max-min fairness）的针对多资源类型（e.g. GPU, CPU）的调度算法


<center> <img src="./img/3/7-3-1-drf.png" ch="500" width="300" height="400" /></center>
<center>图7-3-1. 2个作业的DRF调度实例</center>


$$Cluster \  Resources: [10 \  GPU, 20GB \ RAM] $$

$$
Job \ 1: \\
Total \ GPU \ 1+1 = 2 \ GPU \\
GPU \ Share \ 2/10 = 0.2 \\
Total \ Memory \ 4+4 = 8GB \\
Memory \ Share \ 8/20 = 0.4 \\
SHARE = 0.4 \ [Dominant \ resource \ is \ Memory]
$$

$$
Job \ 2:  \\
Total \ GPU \ 2+3 = 5 \ GPU \\
GPU \ Share \ 5/10 = 0.5 \\
Total \ Memory \ 2+2 = 4GB \\
Memory \ Share \ 4/20 = 0.2 \\
SHARE = 0.5 [Dominant resource is GPU]
$$


## 7.3.4 容量调度

如何让多个小组共享集群？
- 问题：
  - 能否为多个组织共享集群资源？
  - 共享集群资源的同时，如何同时为每个组织提供最小容量保证?
  - 空闲资源能否弹性为其他组织利用？
- 挑战：相比传统容量调度调度，深度学习作业也需要考虑调度GPU及GPU memory
- 设计目标：Utilization, Fairness and SLA

目的：
  - 支持多租(Multi-tenant）资源共享
策略：
- Utilization: 
  - 虚拟集群 (Virtual Cluster）
  - Bonus Resource
- Fairness:
  - Dominant Resource Fairness (DRF)
  - User Limit Factor：控制单用户的可以消耗的最大资源
- SLA 
  - 抢占(Preemption)


## 7.3.5 虚拟集群

虚拟集群 (Virtual Cluster) 映射
- 虚拟集群根据小组的配额进行定义
- 将虚拟集群映射到物理集群

目的：提升资源利用率
策略：
- 虚拟集群根据小组的配额进行定义
- 将虚拟集群映射到物理集群
- 资源被分配给租户(Tenants)
- 每个Tenant构成了一个虚拟集群(VC)

## 7.3.6 抢占式调度

如何让调度兼顾SLA？

- 问题：
共享集群资源被其他组织占用提升了资源利用率但是无法保证SLA?
- 挑战：
在深度学习作业下，被抢占的作业当前只能失败，无法像传统OS上下文切换
- 设计目标：
兼顾有限资源利用和服务等级协议（SLA）

## 7.3.7 实验模拟

此存储库[philly-traces](https://github.com/msr-fiddle/philly-traces) 包含 Microsoft 内部 Philly集群上第一方 (first-party) DNN 训练工作负载的代表性子集。 数据是 ATC’19 中“Analysis of large-scale multi-tenant GPU clusters for DNN training workloads”中描述的工作负载的一个脱敏数据子集。 这项工作是作为 Microsoft Research 的 Project Fiddle 的一部分完成的。

### 7.3.7.1 数据读取
### 7.3.7.2 评测指标设定
### 7.3.7.3 算法实现与评测


## 参考文献

- [Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training Workloads](https://dl.acm.org/doi/10.5555/3358807.3358888)
- Multi-tenant GPU Clusters for Deep LearningWorkloads: Analysis and Implications
- Gandiva: Introspective Cluster Scheduling  for Deep Learning
- Dominant Resource Fairness: Fair Allocation of Multiple Resource Types 
- All You Need to Know about Scheduling Deep Learning Jobs 
- https://github.com/microsoft/pai
- https://www.kubeflow.org/ 
- Kubeflow Pipelines With GPUs
- YARN – The Capacity Scheduler
- Better SLAs via Resource-preemption in YARN’s Capacity Scheduler
- Kube-Batch: Dominant Resource Fairness (DRF)

