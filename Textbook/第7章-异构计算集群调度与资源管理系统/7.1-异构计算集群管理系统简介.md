<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 7.1 异构计算集群管理系统简介

本章将通过启发式实例，介绍异构集群管理系统的设计初衷，需要解决的问题及挑战。

[TOC]


## 7.1.1 多租环境运行的训练作业


<center><img src="./img/1/7-1-1-jobsubmission.png" ch="700" width="600" height="400" /></center>
<center>图7-1-1. 多租环境提交运行作业</center>

多租户（Multi-Tenancy）技术是一种软件架构技术，它实现如何于多用户的环境下共用相同的系统或程序组件，并且仍可确保各用户间数据的隔离性。在企业级深度学习场景下，大型企业有很多机器学习科学家与工程师，组织有大量的GPU服务器，为了组织效率的提升与资源共享，就诞生了针对深度学习场景下设计的多租户的平台系统。又由于平台系统管理的资源是异构（例如, CPU, GPU等）的，所以本章主要围绕的是，管理异构资源，调度深度学习作业的，多租户的，平台系统。

在企业级场景下，多用户共享多GPU服务器相比原来深度学习开发者独占使用服务器进行模型训练，有很大的不同，这也为之后的异构计算集群管理系统(简称，平台，深度学习平台)的设计产生了相应的需求。主要体现在以下几点:

- 多作业(Job)，多用户
  - 每个用户需要不断改进模型，超参数调优，调试与优化作业，这样会提交大量的作业到平台。
  - 多用户，多样的（例如, CV, NLP等）人工智能团队团队有多名工程师，他们会在同一时段向平台申请资源执行作业。
- 作业环境需求多样
  - 目前深度学习的技术栈并不统一，有的用户使用TensorFlow，有的用户使用PyTorch。使用的框架版本也可能不一样，造成底层依赖，例如NVIDIA CUDA等也可能版本不同。用户如果共享机器，需要对依赖的环境互不干扰。
- 作业资源需求多样
  - 用户提交的作业有些是分布式训练作业，对资源需求较多，有些是单机的调试任务，对资源的需求较少。平台需要按需求做好资源的分配，减少资源碎片。
  - 同时对用户来说，不希望作业本身受到其他作业的硬件资源与命名空间内软件的干扰，理想是像使用独占资源一样运行自己的作业。
- 服务器软件环境单一
  - 平台方在采购资源，安装底层操作系统和驱动时，是无法规划和指定未来用户的软件和版本，同时为了运维和部署减少软件兼容性问题，一般将服务器安装统一的操作系统，驱动，并让其版本保持一致，减少运维负担。
- 服务器空闲资源多样
  - 由于用户的作业申请资源多样，作业生命周期多样，造成资源释放后，平台上的空闲资源比较多样，需要设计好调度策略，尽可能提升资源的利用率。

从以上的问题，我们可以看到调度与资源管理系统重要性。它底层抽象并管理计算资源，对上层应用提供隔离并且易用的作业运行时环境，整理来说我们可以理解其为支持深度学习应用的管理分布式GPU集群的操作系统。我们可以总结以下几点来概括平台的使命和重要性：

- 提供人工智能基础架构支持：
  - 深度学习作业调度与管理：根据作业资源需求，分配和回收计算资源，提升利用率的同时，保持一定的公平性等。
  - 异构硬件管理：高效运维，动态扩容，节点问题修复等。管理员和用户可以监控节点及硬件资源状态和利用率等。
- 提升生产力：
  - 用户专注于模型创新，无需关注系统部署，管理。通过镜像等技术，让用户打包软件依赖，简化部署与安装。
  - 运行时隔离资源与软件依赖，让用户像独占一样使用运行时资源，执行作业。
  - 模型，代码和数据共享，加速研究与创新。团队与组织内共享与提供插件化的功能支持，加速创新。

接下来我们通过一个实例介绍后面的很多优化的动机。由于很多基本的神经网络操作符都可以翻译成矩阵乘加运算，我们以一个矩阵乘计算为例介绍，读者可以一起思考其中的优化问题。 

## 7.1.2 作业生命周期


接下来，让我们先了解一下，一个深度学习作业，在平台上是如何提交并执行的，也就是作业的生命周期。

<center><img src="./img/1/7-1-2-cluster.png" ch="500" width="600" height="400"/></center>
<center>图7-1-2. GPU集群</center>

平台上作业生命周期：

1. 作业提交与排队：用户先将作业的依赖环境打包为镜像，并上传到公共镜像中心。之后用户将代码，数据等运行作业需要的素材，上传到平台的文件系统。之后用户可以通过提交工具（例如，Web，命令行，API等），填写资源申请（例如，几块GPU，内存需求），作业启动命令，部署方式，以及镜像，代码和数据的路径。之后点击提交即可。
2. 作业资源分配与调度：平台收到用户的资源申请后，先进行排队，调度器轮询到作业时，根据目前集群中空闲资源状况，根据一定的调度算法，决定作业是在哪些服务器节点启动，如果不满足条件，则继续排队。
3. 作业执行完成与释放：当作业被调度器调度启动，平台会在有空闲资源的节点启动作业，下载镜像，挂载代码和数据的文件系统到节点本地，运行时做好资源限制与隔离，启动作业，执行作业。在作业运行中，平台监控不断收集运行时性能指标和日志，方便用户调试。作业执行完成后，平台会释放申请的资源，并继续分配给其他作业使用。

在这样一个生命周期中，请大家思考集群环境的新问题与挑战可以通过什么技术解决：

1. 如何提交作业与解决环境依赖问题？
2. 如何高效调度作业并分配资源？
3. 如何将启动的作业运行时资源与命名空间隔离？ 

## 小节与讨论

本章我们主要介绍异构计算集群管理系统的应用场景和其中的面对的问题与挑战，启发读者展开后续章节的阅读，并从中理解为何会涉及到相关技术点，其解决了何种问题。

请读者思考，独占使用资源和多租的场景让系统面临何种问题和挑战？

## 参考文献

- https://en.wikipedia.org/wiki/Multitenancy
- https://en.wikipedia.org/wiki/Docker_(software)
- [Ru Zhang, Wencong Xiao, Hongyu Zhang, Yu Liu, Haoxiang Lin, and Mao Yang. 2020. An empirical study on program failures of deep learning jobs. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (ICSE '20). Association for Computing Machinery, New York, NY, USA, 1159–1170. DOI:https://doi.org/10.1145/3377811.3380362](https://dl.acm.org/doi/10.1145/3377811.3380362)
