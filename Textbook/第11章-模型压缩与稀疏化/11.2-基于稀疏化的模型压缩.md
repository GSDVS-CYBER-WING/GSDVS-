<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 11.2 基于稀疏化的模型压缩

- [11.2 基于稀疏化的模型压缩](#112-基于稀疏化的模型压缩)
  - [11.2.1 人工智能系统与稀疏性](#1121-人工智能系统与稀疏性)
  - [11.2.2 深度神经网络的稀疏化与剪枝](#1122-深度神经网络的稀疏化与剪枝)
    - [11.2.2.1 权重稀疏](#11221-权重稀疏)
    - [11.2.2.2  激活稀疏](#11222--激活稀疏)
    - [11.2.2.3 梯度稀疏](#11223-梯度稀疏)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)

## 11.2.1 人工智能系统与稀疏性

​生物研究发现人脑是高度稀疏的。例如当人类识别一只猫时，我们不会仔细检查每一个毛发的纹理，仅仅使用简单的几何边缘就足以做出判别。在交通场景中，当人类看到眼前物体时，我们的神经系统不会处理所有像素，因为那样无法在瞬息万变的场景中迅速做出反应。我们此时仅会关注视野中主要的物体，比如图中用颜色分割的交通参与者（人、车辆）。这些人类认知的本能是千百万年进化与自然选择的结果。同样，在语音识别、医疗成像、自动驾驶、社交网络等各行各业的海量数据中，每种数据都有其内在的结构性。自动学习数据内生的结构性是人工智能算法的核心，数据的结构性带来了信息表达中的稀疏性，高效的人工智能系统应该充分利用这种稀疏性。

<center> <img src=".\img\2\real cat.png"/></center>
<center>图11-2-1 人类的视觉系统是稀疏的，不需要处理所有像素即可迅速做出判断</center>


其实对于AI模型稀疏度的追求早在深度学习风行之前就已得到了广泛的研究，稀疏编码曾经是实现人脸识别主流的技术手段之一[1]。这是因为训练数据的噪声使得模型中包含大量冗余信息，降低了模型的推广（Generalization）能力，而通过模型稀疏化则可以消除这部分冗余从而提升模型精度，但是过度的稀疏则会丢失模型中的关键信息而严重损坏精度指标。在深度神经网络中，对模型尺寸、浮点运算量等性能（Performance）指标的追求成为主要的关注点，模型稀疏度的增加可以持续提升上述性能。如何在模型精度与性能之间寻求最优的折衷是一个复杂的研究话题，也是神经网络稀疏化的研究目标。


<center> <img src=".\img\2\tradeoff.png"/></center>
<center>图11-2-2 稀疏性是人工智能系统度解决模型精度与性能间折衷的主要手段</center>


## 11.2.2 深度神经网络的稀疏化与剪枝

按照深度学习模型中可以被稀疏化的对象，网络稀疏化可以划分为模型稀疏与瞬态（Ephemeral）稀疏两大类。模型稀疏直接改变网络模型中两个最基本的元素——权重与神经元，多应用于网络的推理即前馈运算过程中。权重稀疏对应于非结构化（Unstructured）剪枝，这是一种细粒度（Fine-Grained）的剪枝方式，计算过程中会造成内存访问的不规则性，影响硬件工作效率。也有部分的权重稀疏化工作通过硬件友好型操作，存储连续块的权重从而实现结构化剪枝。神经元稀疏则通过移除整个神经元实现模型压缩，这是一种结构化的（structured)剪枝方式。由于卷积神经网络中权值共享的机制，一个神经元通常也对应着一个卷积核（滤波器）及其卷积计算结果——一个特征图或通道（Channel），因此，滤波器剪枝和通道剪枝也可视为结构化剪枝的类型，剪枝后网络可以有效运行于与原始模型相同的硬件结构之上。

​瞬态稀疏是直接与特定数据样本相关联的，激活稀疏就属于这一类别，特定图像通过激活函数（如ReLU）后将产生特定的稀疏特征图。由于激活函数与单个神经元直接关联，因此激活稀疏也属于结构化稀疏类别。神经网络中的SoftMax操作和dropout操作也可视为激活稀疏，前者属于舍入激活，后者属于随机激活。另一大类的瞬态稀疏是与梯度计算直接相关的，包括梯度、误差及优化器状态，在基于随机梯度下降（SGD）的后向传播算法中通过对梯度值进行稀疏、延迟梯度更新，可以显著减少分布式训练过程中的通信开销。瞬态稀疏中既包括推理时稀疏，如激活稀疏与条件计算，也包括训练时稀疏，主要体现为梯度相关的稀疏。图3总结了按稀疏对象进行分类的树形结构。



<center> <img src=".\img\2\object.png"/></center>
<center>图11-2-3 深度神经网络稀疏性的分类</center>

下文将对权重、激活和梯度三种主要类型的稀疏进行讨论，它们按照不同的视角进行分类的关系如表1所示。结构化剪枝由于对内存访问的规则性，相比非结构化剪枝的到了更多的关注。动态稀疏在训练阶段将剪枝操作与元素再生结合在一起，权重稀疏属于静态稀疏，因为在每次训练迭代过程中，或是整个推理过程中，其连接结构不会发生改变。相比之下，激活及梯度稀疏则属于动态稀疏，无论卷积层的窗口滑动或是输入样本的改变，激活函数都会产生变化的稀疏输出结构。同样，梯度数值也与样本输入直接相关。数据无关（data free）与数据驱动（data driven）类别的划分是依据模型稀疏表现与输入数据的相关性，其与动/静态稀疏是一一对应的。权重稀疏与激活稀疏可以压缩模型推理阶段的网络规模或浮点运算量，梯度稀疏则用于压缩分布式训练情况下的网络通讯带宽。各种分类方式的关系在表2中进行了总结。

​                                             **表2. 深度神经网络稀疏性各种分类方式间的关系** 

|          | 结构/非结构剪枝 | 动态/静态 | 数据驱动方式 | 训练时/推理时 |
| -------- | --------------- | --------- | ------------ | ------------- |
| 权重稀疏 | 非结构化剪枝    | 静态      | 数据无关     | 推理          |
| 激活稀疏 | 结构化剪枝      | 动态      | 数据驱动     | 推理          |
| 梯度稀疏 | N/A             | 动态      | 数据驱动     | 训练          |

### 11.2.2.1 权重稀疏

在大多数类型的深度神经网络中，通过对各层卷积核元素的数值（即网络权重）进行数值统计，人们发现许多层权重的数值分布很像是正态分布（或者是多正态分布的混合），越接近于0，权重就越多。这就是深度神经网络中的权重稀疏现象，一个典型的网络权重分布直方图如下图（a）所示。舍弃掉其中接近0值的权重，相当于在网络中剪除部分连接，如（b）所示，对网络精度影响并不大，这就是权重剪枝。



<center> <img src=".\img\2\weight Gaussian.png"/></center>
<center>图11-2-4 深度网络中存在权重稀疏性:（a）剪枝前的权重分布；（b）剪除0值附近权值后的权重分布；（c）网络微调后的权重分布</center>

这么做的道理是因为权重数值的绝对值大小可以看做重要性的一种度量，较大的权重意味着对最终输出的贡献较大，也相对更加重要，反之则相对不重要。不重要的权重删去对精度影响就应该较小。

<center> <img src=".\img\2\weight prune.png"/></center>
<center>图11-2-5 全连接层中权重（非结构化）剪枝示意图</center>


这种仅依靠权重绝对值大小来排序的剪枝方法通常会带来非结构化的稀疏连接，如图5所示，在计算过程中会引起不规则的内存获取，相反会影响网络的计算效率。所以权重剪枝通常以剪除整个滤波器的方式来实现，图6介绍了一种具体的滤波器剪枝实现算法[4]。假设网络中第i个卷积层中共包含$n_i$个通道（channel），即$n_i$个特征图。$\cal F_{i,j}$ 表示第$i$层后的第$j$个卷积核（滤波器），剪除该滤波器将直接导致第$i+1$层的对应通道（特征图）也被剪除，第$i+1$层之后所有滤波器张量中的对应切片（slice）也将被剪除，如图3中三块蓝色区域标识。假设每个滤波器切片$\cal K$的大小为$k\times k$，则上述剪枝操作将直接减少$k^2\times n_i + k^2\times n_{i+2}$个滤波器权重浮点数的存储空间，并减少$k^2\times n_{i+2}\times h_{i+2}\times w_{i+2} + k^2\times n_i\times h_{i+1}\times w_{i+1}$次浮点数乘法运算开销，达到了网络压缩与加快推理速度的目的。


<center> <img src=".\img\2\filter prune.png"/></center>
<center>图11-2-6 权重剪枝算法示例一：剪除一个完整滤波器对应于剪除一个通道的特征图</center>


如果经过预训练的网络其滤波器参数的稀疏度不足，表现为0值附近的参数数量较少，则上述算法中可供剪除的滤波器数目也将随之较小，从而达不到预期的模型压缩比率。在这种情况下，模型参数正则化（Regularization）就是一种常用的手段来“迫使”模型训练出更加稀疏的滤波器参数分布。如下述公式所示，正则项与训练数据误差项一般共同构成损失函数，并通过计算其梯度实现后向传播的训练过程。

<img src=".\img\2\loss.png" alt="loss" style="zoom:20%;" />

上式中$R(W)$即为正则项，正则因子$\lambda$用以调节两项之间的折衷。常用的正则函数包括$L_1$范数、$L_2$范数、$L_{1,2}$范数等，其定义如下表所示：

​                                                                  **表3. 常用的正则项函数**

|               | 正则项定义                                                |
| ------------- | --------------------------------------------------------- |
| $L_1$正则     | <img src=".\img\2\L1norm.png" alt="L1norm" style="zoom:25%;" /> |
| $L_2$正则     | <img src=".\img\2\L2.png" alt="L2" style="zoom:25%;" />         |
| $L_{1,2}$正则 | <img src=".\img\2\L12.png" alt="L12" style="zoom:25%;" />       |

​文献[5]提出了一种利用批归一化因子（BN）来识别不重要通道的算法，如图8所示。在卷积层之后插入BN层是许多深度网络的通用做法，用以提高训练收敛速度及模型推广能力。BN层中的尺度因子$\gamma $如果接近于0，则其所对应的通道在后续卷积运算中的作用将可以忽略。基于这一考虑，该算法将$L_1$正则项施加于$\gamma$之上，从而迫使BN的尺度因子分布稀疏化，并相应剪除这些接近0值尺度因子所对应的通道、以及对应的滤波器权值连接，从而达到模型压缩目的。


<center> <img src=".\img\2\BN.png"/></center>
<center>图11-2-7 权重剪枝算法示例二：利用BN层中的尺度因子稀疏化计算通道的重要性</center>


即使是移除绝对值接近于0的权重（滤波器）也会带来推理精度的损失。为了恢复网络精度，通常在剪枝之后需要进行再次的训练，这个过程称为微调（fine-tuning）。微调之后的权重分布将部分地恢复高斯分布的特性，如图4（c）所示，同时网络精度也会达到或接近剪枝前的水平。大多数的权重剪枝算法都遵循这一“正则化-剪枝-微调”反复迭代的流程，如图8所示，直到网络规模和精度的折衷达到预设的目标为止。


<center> <img src=".\img\2\three step.png"/></center>
<center>图11-2-8 剪枝算法常用的迭代计算流程</center>


### 11.2.2.2  激活稀疏

神经网络模型中的非线性激活单元（activation)是对人类神经元细胞中轴突末梢（输出）的一种功能模拟。早期的神经网络模型——多层感知机（MLP）中，多采用Sigmoid函数作为激活单元，如图9.（a）所示。然而随着网络层数的加深，Sigmoid函数引起的梯度消失和梯度爆炸问题严重影响了后向传播算法的实用性。为解决上述问题，多种多样新的非线性激活单元被提出，其中ReLU函数是目前应用最为广泛的激活函数，“2D卷积-ReLU激活函数-池化”三个算子相串接而成的基本单元就构成了CNN网络的一个完整层，如下述TensorFlow代码片段所示：

```python
L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')
L1 = tf.nn.relu(L1)
L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],
         strides=[1, 2, 2, 1], padding='SAME')
```

​         ReLU激活函数如图9.（b）所示，其定义为：
$$
\phi(x)=max(0,x)
$$

<center> <img src=".\img\2\ReLU-example.png"/></center>
<center>图11-2-9 激活稀疏效果示意图</center>


该函数使得负半轴的输入都产生0值的输出，图19中的特征图经过非线性激活后，产生激活输出，可以看出激活函数给网络带了另一种类型的稀疏性，红圈标识了特征图中被稀疏化的元素。为了利用上述稀疏特性来压缩模型，文献[6]提出了一种神经元剪枝算法。首先，定义网络中每个神经元经ReLU映射后输出的零值平均百分比（APoZ）指标为：

<img src=".\img\2\APoZ.png" alt="APoZ" style="zoom:40%;" />

这里，$O_c^{(i)}$表示网络第$i$层中第$c$个通道（特征图）的结果，$N$与$M$分别表示用于验证的图像样本个数、及每个特征图的维度，$f\left(  \cdot  \right)$对真的表达式输出1，反之输出0。由于每个特征图均来自一个滤波器（神经元）的卷积及激活映射结果，因此上式衡量了该神经元对一组特定图像的计算结果中0值输出的平均比例。图10给出了在VGG-16网络的CONV5-3层中，利用50,000张ImageNet图像样本计算得到的所有512个神经元的APoZ指标分布图。可以看出大多数神经元的该项指标都分布在93%附近。实际上，该网络中共有631个神经元的APoZ值超过90%。激活函数的引入反映出VGG网络存在着大量的稀疏与冗余性。

<center> <img src=".\img\2\histo-APoZ.png"/></center>
<center>图11-2-10 激活稀疏算法示例：ReLU激活函数输出结果中存在高度的稀疏性。</center>


### 11.2.2.3 梯度稀疏

在第五章中我们已经看到，大模型（如BERT）由于参数量庞大，单台主机难以满足其训练时的计算资源需求，往往需要借助分布式训练的方式在多台节点（worker）上协作完成。采用分布式随机梯度下降（Distributed SGD）算法可以允许$N$台节点共同完成梯度更新的后向传播训练任务。其中每台主机均保存一份完整的参数拷贝，并负责其中$1/N$参数的更新计算任务。按照一定时间间隔，节点在网络上发布自身更新的梯度，并获取其他$N-1$台节点发布的梯度计算结果，从而更新本地的参数拷贝。整个协作过程如图14所示。


可以看出，随着参与训练任务节点数目的增多，网络上传输的模型梯度数据量也急剧增加，网络通信所占据的资源开销将逐渐超过梯度计算本身所消耗的资源，从而严重影响大规模分布式训练的效率。另一方面，大多数深度网络模型参数的梯度是高度稀疏的，研究表明在分布式SGD算法中，99.9%的梯度交换都是冗余的。图15显示了在AlexNet的训练早期，各层参数梯度的幅值还是较高的。但随着训练周期的增加，参数梯度的稀疏度显著增大，大约30个训练周期后，各层梯度稀疏度都趋于饱和。显然，将这些0值附近的梯度进行交换，对网络带宽资源是一种极大的浪费。

<center> <img src=".\img\2\Alex grad sparse.png"/></center>
<center>图11-2-11 深度神经网络训练中的各层梯度值存在高度稀疏特性。</center>

梯度稀疏的目的在于压缩分布式训练时被传输的梯度数据，减少通信资源开销。由于SGD算法产生的梯度数值是高度噪声的，移除其中并不重要的部分并不会显著影响网络收敛过程，与之相反，有时还会带来正则化的效果，从而提升网络精度。梯度稀疏实现的途径包括：1）预设阈值：在网络上仅仅传输那些幅度超过预设阈值的梯度；2）预设比例：在网络上传输根据一定比例选出的一部分正、负梯度更新值；3）梯度丢弃：在各层梯度完成归一化后，按照预设阈值丢弃掉绝大多数幅值较低的梯度。一些梯度稀疏算法在机器翻译任务中可以节省99%的梯度交换，而仅带来0.3%的模型精度损失；可以将ResNet-50模型训练的梯度交换参数量从97MB压缩为0.35MB而并不损失训练精度[9]。

<center> <img src=".\img\2\gradient sparse.png"/></center>
<center>图11-2-11 通过梯度稀疏可以在分布式训练任务中大幅减少通信时间开销从而提升模型训练效率[9]。</center>

## 小结与讨论

神经网络稀疏化尽管近年来已经取得了丰富的研究成果，但是作为一个新的研究方向，并没有完全成熟的知识体系，许多固有结论不断地被打破和重建，深度网络模型的稀疏与压缩仍然具有巨大的潜力和研究空间。下面对现有剪枝方法进行小结，并指出未来该领域的部分挑战性问题。

- 早期的剪枝工作多针对非结构化剪枝及启发式方法，当前结构化剪枝及自动化剪枝受到越来越多的关注，因为其更易获得实际的模型加速机会及更高的模型压缩率。
- 卷积层相比全连接层由于其冗余性更小，因而剪枝方法的设计更具挑战性。因此，那些没有大规模全连接结构的神经网络，如ResNet、GoogLeNet、DenseNet等，就要比拥有较多全连接结构的网络，如VGG、AlexNet等更加难于压缩。
- 神经元剪枝相比权重剪枝更易损失模型精度，训练阶段的梯度则拥有最多的稀疏度。如何优化模型稀疏度与剪枝后精度间的折衷仍是当前该领域的研究重点。
- 图8所示的网络剪枝一般流程也并不是一成不变的，最新的研究表明，对于随机初始化网络先进行剪枝操作再进行训练，有可能会比剪枝预训练网络获得更高的稀疏度和精度。因此，究竟剪枝后的残余连接结构与残余权重值两者哪个更为关键，就成为一个开放的研究问题。


## 参考文献

- Wright J, Yang A Y, Ganesh A, et al. Robust face recognition via sparse representation. IEEE transactions on pattern analysis and machine intelligence, 2008, 31(2): 210-227.
- 纪荣嵘,林绍辉,晁飞,吴永坚,黄飞跃.深度神经网络压缩与加速综述.计算机研究与发展,2018,55(09):1871-1888.
- Hoefler T, Alistarh D, Ben-Nun T, et al. Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks. Journal of Machine Learning Research, 2021, 22(241): 1-124.
- Li H, Kadav A, Durdanovic I, et al. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.
- Liu Z, Li J, Shen Z, et al. Learning efficient convolutional networks through network slimming. Proceedings of the IEEE international conference on computer vision. 2017: 2736-2744.
- Hu H, Peng R, Tai Y W, et al. Network trimming: A data-driven neuron pruning approach towards efficient deep architectures. arXiv preprint arXiv:1607.03250, 2016.
- Ren M, Pokrovsky A, Yang B, et al. Sbnet: Sparse blocks network for fast inference. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 8711-8720.
- Aji A F, Heafield K. Sparse communication for distributed gradient descent. arXiv preprint arXiv:1704.05021, 2017.
- Lin Y, Han S, Mao H, et al. Deep gradient compression: Reducing the communication bandwidth for distributed training. arXiv preprint arXiv:1712.01887, 2017.
- Deng L, Li G, Han S, et al. Model compression and hardware acceleration for neural networks: A comprehensive survey. Proceedings of the IEEE, 2020, 108(4): 485-532.













