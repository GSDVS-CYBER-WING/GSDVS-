<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 8.1 推理系统简介

- [8.1 推理系统简介](#81-推理系统简介)
  - [8.1.1 对比推理与训练过程](#811-对比推理与训练过程)
  - [8.1.2 推理系统的优化目标与约束](#812-推理系统的优化目标与约束)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)
## 8.1.1 对比推理与训练过程

<center> <img src="./img/1/8-1-1-app.png" width="500" height="180" /></center>
<center>图8-1-1. 典型深度学习推理应用</center>

深度学习模型的生命周期

<center> <img src="./img/1/8-1-2-lifecycle.png" width="500" height="200" /></center>
<center>图8-1-2. 深度学习模型的生命周期</center>

训练阶段:
- 数据处理
- 模型训练

推理阶段:
- 部署
- 推理

<center> <img src="./img/1/8-1-3-traininfer.png" width="500" height="300" /></center>
<center>图8-1-3. 模型训练与推理阶段</center>


推理相比训练的新特点与挑战

- 模型被部署为长期运行的服务
  - 服务有明确对请求的低延迟高吞吐需求
- 推理有更苛刻的资源约束
  - 更小的内存，更低的功耗等
- 推理不需要反向传播梯度下降
  - 可以牺牲一定的数据精度
- 部署的设备型号更加多样
  - 需要定制化的优化


模型部署与推理实例

```
# Convert the Tensorflow or other framework model to Serving System model format (UFF).
…
uff_model = uff.from_tensorflow(tf_model, OUTPUT_NAMES)
# Import the UFF model to TensorRT and build an engine.
…
engine = trt.utils.uff_to_trt_engine(G_LOGGER, uff_model, parser, 1, 1 << 20)
# Get the test image. 
…
img = Image.open(path)
…
# Create the context for the engine
context = engine.create_execution_context()
...
# Copy input to device and execute model
… 
bindings = [int(d_input), int(d_output)]
…
cuda.memcpy_htod_async(d_input, img, stream)
context.enqueue(1, bindings, stream.handle, None)
# Last, get the prediction and transfer prediction back
…
cuda.memcpy_dtoh_async(output, d_output, stream)
…
print("Prediction: ", LABELS[np.argmax(output)])
>>> Prediction:  n01608432 kite # The result is right due to imagenet_1000.txt does not include 'seagull’.
```

<center> <img src="./img/1/8-1-4-servingsys.png" width="500" height="200" /></center>
<center>图8-1-4. 推理服务系统</center>


## 8.1.2 推理系统的优化目标与约束

<center> <img src="./img/1/8-1-5-recommendsys.png" width="130" height="200" /></center>
<center>图8-1-5. 推荐系统</center>


在线推荐系统的服务需求

例如某在线新闻APP公司希望部署内容个性化推荐服务并期望该服务能满足以下需求：

- 低延迟：
  - 互联网上推荐文章延迟（<100毫秒）
- 高吞吐：
  - 突发新闻驱动的暴增人群的吞吐量需求
- 扩展性：
  - 扩展到不断增长的庞大的用户群体
- 准确度：
  - 随着新闻和读者兴趣的变化提供准确的预测 

推理系统部署灵活性需求

<center> <img src="./img/1/8-1-6-flexibility.png" width="430" height="200" /></center>
<center>图8-1-6. 推理系统部署需要支持多种框架和硬件</center>

机器学习服务的部署，优化和维护困难且容易出错
- 框架多样：
  - 大多数框架都是为训练设计和优化	
  - 开发人员需要将必要的软件组件拼凑在一起
  - 跨多个不断发展的框架集成和推理需求
- 硬件多样：
  - 多种部署硬件的支持

设计推理系统的优化目标

- 延迟(Latency):
  - 满足服务等级协议的延迟
- 吞吐量(Throughputs):
  - 暴增负载的吞吐量需求
- 效率(Efficiency): 
  - 高效率，低功耗使用GPU, CPU
- 灵活性(Flexibility): 
  - 支持多种框架, 提供构建不同应用的灵活性
- 扩展性(Scalability):
  - 扩展支持不断增长的用户或设备

推理系统的约束

<center> <img src="./img/1/8-1-7-constraint.png" width="300" height="200" /></center>
<center>图8-1-6. 推理系统部署需要支持多种框架和硬件</center>

- SLA对延迟的约束
- 资源约束
  - 设备端电池约束
  - 设备与服务端内存约束
  - 云端资源的预算约束
  - …
- 准确度(Accuracy)约束
  - 使用近似模型产生的一些误差可以接受

 ## 小结与讨论

深度学习推理系统设计需要考虑多目标和约束
推理系统相比传统服务系统有哪些新的挑战？
云和端的服务系统有何不同的侧重和挑战？

## 参考文献

- [Park, Jongsoo et al. “Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications.” ArXiv abs/1811.09886 (2018): n. pag.](https://arxiv.org/abs/1811.09886)
- [Crankshaw, Daniel et al. “Clipper: A Low-Latency Online Prediction Serving System.” NSDI (2017).](https://www.usenix.org/system/files/conference/nsdi17/nsdi17-crankshaw.pdf)
- [Denis Baylor, Eric Breck, Heng-Tze Cheng, Noah Fiedel, Chuan Yu Foo, Zakaria Haque, Salem Haykal, Mustafa Ispir, Vihan Jain, Levent Koc, Chiu Yuen Koo, Lukasz Lew, Clemens Mewald, Akshay Naresh Modi, Neoklis Polyzotis, Sukriti Ramesh, Sudip Roy, Steven Euijong Whang, Martin Wicke, Jarek Wilkiewicz, Xin Zhang, and Martin Zinkevich. 2017. TFX: A TensorFlow-Based Production-Scale Machine Learning Platform. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '17). Association for Computing Machinery, New York, NY, USA, 1387–1395. DOI:https://doi.org/10.1145/3097983.3098021](https://research.google/pubs/pub46484/)
- [Olston, Christopher et al. “TensorFlow-Serving: Flexible, High-Performance ML Serving.” ArXiv abs/1712.06139 (2017): n. pag.](https://arxiv.org/abs/1712.06139)
- [Jeong-Min Yun, Yuxiong He, Sameh Elnikety, and Shaolei Ren. 2015. Optimal Aggregation Policy for Reducing Tail Latency of Web Search. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '15). Association for Computing Machinery, New York, NY, USA, 63–72. DOI:https://doi.org/10.1145/2766462.2767708](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/samehe-2015sigir.optimalaggregation.pdf)
- [Cheng, Yu et al. “A Survey of Model Compression and Acceleration for Deep Neural Networks.” ArXiv abs/1710.09282 (2017): n. pag.](https://arxiv.org/abs/1710.09282)
- [CSE 599W: System for ML - Model Serving](https://dlsys.cs.washington.edu/)
- https://developer.nvidia.com/deep-learning-performance-training-inference 
- [Han, Song et al. “Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding.” arXiv: Computer Vision and Pattern Recognition (2016): n. pag.](https://arxiv.org/abs/1510.00149) 
- [Song Han, Jeff Pool, John Tran, and William J. Dally. 2015. Learning both weights and connections for efficient neural networks. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1 (NIPS'15). MIT Press, Cambridge, MA, USA, 1135–1143.](https://arxiv.org/abs/1506.02626)
- [DEEP LEARNING DEPLOYMENT WITH NVIDIA TENSORRT](https://developer.nvidia.com/blog/deploying-deep-learning-nvidia-tensorrt/)
- [Jonathan Ragan-Kelley, Connelly Barnes, Andrew Adams, Sylvain Paris, Frédo Durand, and Saman Amarasinghe. 2013. Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines. SIGPLAN Not. 48, 6 (June 2013), 519–530. DOI:https://doi.org/10.1145/2499370.2462176](https://people.csail.mit.edu/jrk/halide-pldi13.pdf)
- [Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Meghan Cowan, Haichen Shen, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy. 2018. TVM: an automated end-to-end optimizing compiler for deep learning. In Proceedings of the 13th USENIX conference on Operating Systems Design and Implementation (OSDI'18). USENIX Association, USA, 579–594.](https://arxiv.org/abs/1802.04799)
- [8-bit Inference with TensorRT](https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf)