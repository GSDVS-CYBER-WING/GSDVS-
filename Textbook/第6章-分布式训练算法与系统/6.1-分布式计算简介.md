<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 6.1 分布式计算简介

- [6.1 分布式计算简介](#61-分布式计算简介)
  - [6.1.1 串行计算到并行计算的演进](#611-串行计算到并行计算的演进)
  - [6.1.2 并行计算加速定律](#612-并行计算加速定律)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)
  
在了解具体的分布式技术之前，让我们首先简要回顾作为其基础的并行计算的一些基本概念。

## 6.1.1 串行计算到并行计算的演进

计算机最初的设计是采用单处理器串行执行的处理方式。这样的硬件结构简单，软件的编写也比较容易。例如，当给定一个具体问题时，设计串行算法求解是较为简单直接的。之后我们便可以将求解算法的过程书写成对应的计算机程序，由编译器翻译为机器能够执行的指令，发送给硬件运行。如下图所示，程序的指令依照顺序，连同输入的数据送入中央处理器核心（CPU core），经过处理计算产生计算的结果数据。

<center><img src="./img/image1b.png" width="500" height="" /></center>
<center>图6-1-1: 使用单处理器的程序处理过程 </center>

正由于算法的设计较为容易、硬件结构简单成本低廉等多方面的原因，人们日常生活中接触到的计算机在其诞生后的数十年内都是单核心中央处理器(single-core CPU)，也就是单个中央处理器中仅有一个处理核心。

**从串行计算转向并行计算**

但是串行计算的处理能力受限于单处理器的运算能力。虽然单处理器的能力在不断发展，但当问题规模
(数据量+计算量)增大的速度更大，以至于单一设备处理速度无法满足时，矛盾就会显现。比如下图，包括天气预测在内的大量科学计算问题在很早的时候就遇到了这样的矛盾而转向并行计算[<sup>[1]</sup>](#IntroParallel)。个人电脑方面在2005年前后也遇到了类似的矛盾，而后由Intel和AMD分别推出了多核处理器予以应对。

<center><img src="./img/image2.png" width="600" height="" /></center>
<center><img src="./img/image3.png" width="600" height="" /></center>
<center><img src="./img/image4.png" width="600" height="" /></center>
<center>图6-1-2: 并行计算涉及的大规模运算 (<a href=https://computing.llnl.gov/tutorials/parallel_comp>图片来源</a>)</center>

**深度学习的计算复杂度**

相比于传统高性能计算，深度学习理论虽然已存在数十年（例如反向梯度传播早在1970已被提出
[Seppo Linnainmaa](https://en.wikipedia.org/wiki/Seppo_Linnainmaa)）[<sup>[2]</sup>](#BackwardTheory)但是在2010年后才逐渐转向实用。

一个重要的原因就是深度学习算法基于统计的高阶非线性模型拟合，计算的复杂度从原理上即高于其它算法。更严峻的问题是，为了追求更高的算法精准度，深度学习模型的规模也同步高速增长。这对于模型的计算，尤其是训练带来了极大的挑战。

**更优的模型 -&gt; 更大的计算复杂度**

下图通过近年多个模型，展示了深度学习模型中的准确度和训练计算量关系[<sup>[3]</sup>](#BenchAnalysisDNN)。图中的纵轴用模型"前5个返回结果的准确度"表示其准确性，横轴表示计算的复杂度（单位：十亿浮点数），每个圆盘代表一个模型，其半径表示参数量（单位：百万）。

<center><img src="./img/image5.png" width="600" height="" /></center>
<center>图6-1-3: Top-5准确率（纵轴）与计算复杂程度（横轴：单次神经网络前向计算量）的关系，通过圆盘的尺寸表示模型参数量的大小关系 <Top-5 accuracy vs. computational complexity (single forward pass) *Benchmark Analysis of Representative Deep Neural Network Architectures*> (<a href=https://arxiv.org/pdf/1810.00736.pdf>图片来源</a>) </center>

从图中我们可以明显看出：整体而言，伴随着准确率的提升，模型单次迭代所需的计算量和模型的参数量是同步增加的。这说明，为了得到准确度更高的模型，我们需要花费更多的参数存储，以及更高的计算量。
考虑固定的计算能力，更高的计算量意味着更长的处理时间。
因此在这样的趋势之下，深度学习训练的耗时已经成为一个亟待解决的问题。例如，语言模型BERT-Large如果采用单个CPU训练，则需要以年为单位计算的时间。
<!-- //NOTE not real single processor -->

因此，类似于高性能计算，大规模深度学习的训练也求助于并行计算来解决单处理器算力不足与计算需求过高的矛盾。如下图所示，从原理上来讲，并行计算通过**并行算法**将问题的求解进行划分，并将编译的指令分发给**分布式系统**中的多处理器并行执行。这样一来，所有的计算量被分摊到多个计算单元之上，相比于串行计算，并行计算中的每个计算单元只需要负责部分的计算，缩短了整体的计算时间。

<center><img src="./img/image6b.png" width="800" height="" /></center>
<center>图6-1-4: 采用多处理器并行执行程序的过程 </center>

在并行算法和并行处理硬件的加持下，并行的处理可以极大缩短深度学习的计算时间：
例如，在BERT-Large的训练中，如果用单枚包含80个并行硬件执行单元的V100
GPU训练，则可以将训练耗时降至1个月多。
而通过将1472个V100 GPU相互连结，科学家们甚至可以实现47分钟完成这个模型的训练。

我们可以清楚的看到，随着计算的并行化程度的增大，计算的时间得到了数个量级的改善。这对于探索大规模问题有着不可替代的意义。

## 6.1.2 并行计算加速定律

为了更为精确地分析并行计算的加速，有效地指导我们制定并行策略，我们需要用到一些加速定律。

-   阿姆达尔定律 (Amdahl's law)

[阿姆达尔定律](<https://en.wikipedia.org/wiki/Amdahl%27s_law>)[<sup>[4]</sup>](#Amdahl)可以表达为以下公式：

$$
S = \frac{1}{(1-p)+\frac{p}{N}}
$$

其中：

-   $S$ 是整个任务并行化后执行的理论加速比

-   $p$ 是任务中可并行化部分所占整个任务的比例

-   $N$ 是任务中可并行化部分投入的资源，亦即处理器数


阿姆达尔定律主要分析在问题规模不变的情况下，增加处理能力能够带来多大的加速率。其关于加速极限的基本结论是：存在加速的极限，为非可并行计算的占比之倒数$\frac{1}{1-p}$。该定律指导我们设计模型的时候需要尽量考虑增大可并行部分的比例。换言之，更适合并行加速的模型能够获得更高的计算效率，往往更容易提升规模以获得更好的准确率。注意力（attention）模型替代LSTM模型用于自然语言处理的过程便是这样一个例子，原本顺序执行、难以并行化的LSTM逐渐被更容易并行执行的注意力模型淘汰。

-   Gustafson定律 (Gustafson’s law)

[Gustafson定律](<https://en.wikipedia.org/wiki/Gustafson%27s_law>)[<sup>[5]</sup>](#Gustafson)可表达为如下公式：

$$
S = (1-p) + p \times N
$$

其中：

-   $S$ 是整个任务并行化后执行的理论加速比

-   $p$ 是任务中可并行化部分所占整个任务的比例

-   $N$ 是处理器数

与阿姆达尔定律悲观的加速极限相比，Gustafson定律的设定允许计算问题的规模随着处理能力的增加而相应地增长，从而避免了加速比提升受限的问题。这和机器学习的许多问题更为契合。例如，首先给定的计算力，然后处理问题的规模是可以通过模型结构、数据量、超参数等方面的调整来匹配计算力。

## 小结与讨论

本节通过介绍传统并行计算的发展和机器学习演进的相似点，引导读者思考分布式机器学习的必要性。又通过并行相关理论的简单介绍，希望能够启迪读者重新审视分布式机器学习的问题定义和研究目的。

## 参考文献

<div id="IntroParallel"></div>

1. [Introduction to Parallel Computing Tutorial](https://hpc.llnl.gov/documentation/tutorials/introduction-parallel-computing-tutorial)

<div id="BackwardTheory"></div>

2. [Seppo Linnainmaa, Algoritmin kumulatiivinen pyoristysvirhe yksittaisten pyoristysvirheiden taylor-kehitelmana](https://people.idsia.ch/~juergen/linnainmaa1970thesis.pdf)

<div id="BenchAnalysisDNN"></div>

3. [Benchmark Analysis of Representative Deep Neural Network Architectures](https://arxiv.org/pdf/1810.00736.pdf)

<div id="Amdahl"></div>

4. [阿姆达尔定律](https://en.wikipedia.org/wiki/Amdahl%27s_law)

<div id="Gustafson"></div>

5. [Gustafson定律](https://en.wikipedia.org/wiki/Gustafson%27s_law)


<div id="BERT47min"></div>

6. [NVIDIA Tensor Core GPUs Train BERT in Less Than An Hour](https://developer.nvidia.com/blog/training-bert-with-gpus/)