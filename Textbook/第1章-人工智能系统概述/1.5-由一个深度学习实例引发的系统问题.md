<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 1.5 由一个深度学习实例引发的系统问题


- [1.5 由一个深度学习实例引发的系统问题](#15-由一个深度学习实例引发的系统问题)
  - [1.4.1 深度学习训练实例与背后潜在的系统问题](#141-深度学习训练实例与背后潜在的系统问题)
  - [1.4.2 卷积算子的底层实现与性能预估](#142-卷积算子的底层实现与性能预估)
  - [1.4.3 更大的模型所产生的问题](#143-更大的模型所产生的问题)
  - [1.4.4 更大范围的系统问题](#144-更大范围的系统问题)
  - [参考文献](#参考文献)

## 1.4.1 深度学习训练实例与背后潜在的系统问题

```
# 本实例来源PyTorch官方实例 https://github.com/pytorch/examples/blob/main/mnist/main.py 
```

## 1.4.2 卷积算子的底层实现与性能预估

## 1.4.3 更大的模型所产生的问题

- 更大的批次
- 更大的模型

## 1.4.4 更大范围的系统问题

- 更多的超参数组合与模型结构探索
  - 之前我们看到的实例本身是单个模型的样例，但是深度学习模型可以通过变换其中的超参数和模型结构获取和训练更好的结果，这种探索式的过程也叫做自动化机器学习，读者可以参考第9章-自动化机器学习系统了解相关领域内容与挑战。
- 共享的资源与多租的环境
  - 如果我们现在的GPU等训练资源都是被公司或组织机构集中管理，用户需要共享使用资源进而提升资源整体利用率，那么在这种环境下系统如何提供给算法工程师接近单机的使用环境体验让算法工程师更加简便高效的使用资源？读者可以参考第7章-异构计算集群调度与资源管理系统进行了解平台如何应对当前的挑战。
- 假设数据无法离线提前准备好？
  - 如果数据没有提前准备好，需要系统提供更加多样的训练方式，深度学习系统需要不断与环境或者模拟器交互，通过强化学习方式进行训练，读者可以参考第10章-强化学习系统进行了解，强化学习系统如何在更复杂与多样的场景下进行模型训练以及数据获取。
- 数据和人工智能模型的安全与隐私如何保障？
  - 当前深度学习为数据驱动的方法，同时会产生交付的模型文件，模型泄露，篡改以及本身的缺陷会造成潜在的安全风险。如何保障深度学习整体的安全与隐私相比传统安全领域遇到了新的挑战，读者可以参考第12章-人工智能安全与隐私进行了解。
- 之前我们大部分了解的是针对人工智能负载做系统设计也称作System for AI，反过来我们也可以思考如何通过人工智能这种数据驱动的方法反过来指导系统设计与优化，也就是AI for System，读者可以参考第13章-人工智能优化计算机系统进行了解。


## 参考文献
- 