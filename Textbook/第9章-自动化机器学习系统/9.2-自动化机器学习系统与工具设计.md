<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 9.2 自动化机器学习系统与工具设计

- [9.2 自动化机器学习系统与工具设计](#92-自动化机器学习系统与工具设计)
  - [9.2.1 自动化机器学习系统概述](#921-自动化机器学习系统概述)
  - [9.2.2 探索式训练过程](#922-探索式训练过程)
  - [9.2.3 自动化机器学习系统编程范式](#923-自动化机器学习系统编程范式)
  - [9.2.4 自动化机器学习系统优化前沿](#924-自动化机器学习系统优化前沿)
  - [9.2.5 自动化机器学习工具概述与实例分析](#925-自动化机器学习工具概述与实例分析)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)


## 9.2.1 自动化机器学习系统概述

***框架设计的理念和目标***

自动机器学习工具能够使机器学习模型的设计和调优变得可扩展，以催化机器学习广泛赋能各个行业、各种场景的进程。

一个自动化机器学习工具的设计需要兼顾很多方面，如易用性(easy-to-use)、灵活性(flexibility)、扩展性(scalability)和有效性(effectiveness)。

- 易用性是指用户容易上手，对工具的学习曲线较为平缓。易用性不仅是文档的问题，更多的是工具中各级用户接口的设计。在自动化机器学习中，易用性表现在两个层面，一是用户已经有了初步的模型，如何利用工具快速调优模型到满足应用需求。二是用户没有模型，仅有应用需求（和数据），工具如何协助用户获得满足需求的模型。

- 灵活性是指用户不仅可以利用工具提供的算法快速得到效果不错的模型，还可以通过细粒度的配置和定制进一步提升模型的效果。通常工具是提供多层用户接口来支持各个层级的定制化。

- 扩展性是指一个模型调优任务可以灵活调整使用的计算资源的多少，可以使用单台机器，也可以使用几百几千台机器。

- 有效性是指工具提供的流程和算法可以有效得到好的模型。

***框架设计概览***

目前，已经有很多自动机器学习工具，在功能上主要分为两类：面向端到端(end-to-end)自动模型生成的自动机器学习工具和面向开发和定制的自动机器学习工具。前者在使用接口上更加简单，通常提供`tool.fit(training_data)`和`tool.predict(one_sample)`的使用接口。其中，`fit`是根据用户提供的目标训练数据，得到最优的机器学习模型；`predict`是根据搜索得到的最优模型做模型推理(inference)。使用这类接口的自动机器学习工具有autosklearn、autokeras。面向开发和定制的机器学习工具相比于前者提供了更大的灵活性。它通常提供丰富的算法库，更加灵活的配置接口。用户可以灵活选择使用什么样的搜索算法，配置模型的优化目标，等更灵活的定制需求。这类工具包括NNI、Ray。这两种类别并不冲突，而是可以看作一种互补，即前者可以架构于后者之上。在面向开发的自动机器学习工具之上可以构建各种端到端的自动机器学习应用。

在工具的使用和部署方式上又可以分为两类：以工具库(library)的形式和以服务的形式（或称之为云原生的形式）。以工具库的形式通常安装非常简单，只需一行安装命令，相对轻量，可以安装在不同的系统和环境中。另一类是以服务的形式，这类工具直接以服务的形式部署在云上，并关联的解决数据存储、实验管理、可视化分析等一系列功能。使用体验更好，但是相应的会让用户花费更高的成本。这两类也是不冲突的，一个好的以工具库形式设计的自动机器学习工具也可以以服务的形式部署在云上。

自动机器学习工具的设计需要权衡通用性和定制化。过于通用会使工具离实际应用太远，无法很好支持自动机器学习任务。过于定制化，又使自动机器学习应用很难扩展，沦为某种形式的软件外包。这就要求在自动机器学习工具的设计过程中，提取共性，抽象出通用模块，设计具有可扩展性的接口，合理拆分系统层级。

自动机器学习工具有两大部分构成。一部分是算法，即各类超参数搜索算法，神经网络结构搜索算法，模型压缩算法，等等在模型设计、调优和部署过程中涉及到的各种算法和流程。另一部分是平台和系统，用以支持算法的高效运行的。

算法部分已经在上一节做了介绍。接下来，从平台和系统方面，分别从统一的运行模式，下一代编程范式，和前沿的系统优化，介绍自动机器学习系统中的几个关键组成。最后使用自动机器学习工具NNI做实例分析。

## 9.2.2 探索式训练过程

***探索式训练是前沿论文共同影射出来的方向***

在机器学习模型的设计、调优和部署的过程中，试错(trial-and-error)是开发人员的统一行为模式。机器学习模型很难通过一次性的模型设计就满足应用的要求，而通常是经过反复的迭代和调优。自动机器学习是对开发人员调优模型的一种模拟，因此它也遵循试错的行为模式，就像图9-1-1中展示的那样。

对每一个具体的机器学习应用，机器学习模型都会有一个设计和调优的可行域，在该应用上最优的机器学习模型存在于这个可行域中。在这个可行域中搜索最优模型被称之为**探索式训练**。

探索式训练的本质是将传统的单模型训练转变为在一个模型空间（即搜索空间）中调优和训练相结合，将模型调优囊括到模型训练的过程中。图9-2-1展示了神经网络结构搜索中几种探索式训练的例子。如图9-2-1(a)所示，在模型设计过程中，将一层中的算子替换成其他类型算子是一种常见操作。模型中算子之间的连接也会影响模型的表现，所以改变连接也是常见的调优方式，比如增加跳线(skip connection)。另外开发人员也会基于某种规则对模型做变化，比如在模型中所有Conv2d算子的后面添加BatchNorm算子，或者将BatchNorm统一替换成LayerNorm。如图9-2-1(b)所示，开发人员会尝试将某种模型结构做适当泛化。比如对一个特定的Inception cell的多分支结构做泛化，尝试不同的分支数，以及在不同分支上尝试不同的算子。如图9-2-1(c)所示，开发人员也会设计若干规则，在一个基础模型上不断的应用这些规则是模型逐渐变大。

<center> <img src="./img/9-2-1-exploratory-training.png"/></center>
<center>图9-2-1. 探索式训练的例子</center>

通常这些对模型的细粒度的设计和调优是专家不擅长的，因此将这类调优和模型训练结合到一起可以让开发人员更专注于模型骨架的设计。

## 9.2.3 自动化机器学习系统编程范式

***前沿的编程接口***

探索式训练使开发人员在模型设计过程中可以含糊得表达一个大致的模型设计思虑，而让自动化机器学习通过搜索的方式丰富模型的各个细节。如何设计一个服务于这种需求的编程范式是一个挑战，它需要既可以简单得表达模型空间又具有较强的表达能力。

从图9-2-1以及开发人员设计模型的行为模式，可以看出模型的设计和调优本质上是一个不断变化(mutate)模型的过程。因此表述一个模型空间等价于表述一组变化范围。例如，神经网络模型中的一层中初始使用的是Conv3x3算子，开发人员可以通过模型变化将其替换成Conv5x5，也是替换成Maxpool，来验证模型效果是否有提升. 这里模型的变化是由变化方式（即算子替换）和在该变化方式上的选择空间（即上述三个希望尝试的算子）构成的。再例如图9-2-1(b)中的模型变化，其变化方式是增加删除分支和替换分支上的算子，变化空间是候选的分支数量和候选算子。

模型变化(mutation)就是表达模型空间的一种编程抽象。它将模型看作一个计算流图(data flow graph)，提供两类原语(primitive)：一类是图操作原语，即图的增删查改，用以灵活的变化模型；另一类是表达变化空间的原语，如API *choice()*是从多个候选中选择一个。一个完整的模型空间是由一个初始模型(base model)和模型变化构成的。图9-2-2是用模型变化描述出的模型空间的一个示例，子图(a)是初始模型。该示例中的模型空间是将模型第三层"model/maxpool"替换成一个类似inception cell的层。这个层可以有2到5个分支，每个分支上的算子可以从三个候选算子中选一个。子图(b)描述了该模型变化。子图(c)是利用上述编程范式实现的一个模型空间。"InceptionMutator"是模型变化的伪代码，它在
"mutate"函数中选择具体分支数（第9行），对于每个分支从候选算子中选择一个连接到模型中。最后使用"apply_mutator"将这个模型变化应用模型的目标位置上，即"model/maxpool"。

<center> <img src="./img/9-2-2-modelspace.png"/></center>
<center>图9-2-2. 一个模型空间的示例</center>

通过模型变化表述模型空间的这种新编程范式可以将模型空间的表达，搜索算法，和系统优化有机地结合起来。
  - 任意的模型空间可以由该编程范式灵活表达；
  - 通过该编程接口表达的模型空间可以被搜索算法正确解析，大大提升搜索算法的可复用性。
  - 系统层面，模型在探索式训练的过程中做的任何变化都可以被精准定位，使得模型和模型之间的关系变得非常清晰，从而打开了跨模型优化的空间。

***更加易用的编程接口***

模型变化是表达模型空间的核心抽象，虽然具有很大的灵活性，但是在编程的易用性上稍有欠缺。因此在该编程范式之上可以提供更加简洁易用的语法糖（syntactic sugar）。在网络结构搜索中，有三个API较为常用，可以构建出大部分模型空间。它们是"LayerChoice"，"InputChoice"，和"ValueChoice"。"LayerChoice"是创建模型中的一层，该层的算子是从一系列候选算子中选择一个。"InputChoice"是创建连接，允许从一些列候选张量(tensor)中选择一个或者多个张量。"ValueChoice"是从多个候选数值中选择一个，比如用于选择dropout rate的大小。这些API可以直接编写PyTorch或者Tensorflow的模型代码中使用，将编写的模型变为一个模型空间。

## 9.2.4 自动化机器学习系统优化前沿

***自动机器学习系统架构***

自动机器学习系统一般由四部分构成，如图9-2-3所示。模型空间分析器将用户编写的模型空间解析成系统可以操作和优化的中间表达(intermediate representation)。然后模型生成器可以进行模型生成。生成什么模型是由探索式训练控制器决定。控制器中会运行一个搜索算法，来决定要探索哪些模型。生成的模型可以由跨模型优化器做一系列优化加速。最后优化后的模型被放到模型训练平台（如Kubernetes）上训练。训练的结果（如模型精度）会反馈给探索式训练控制器用于指导之后的模型生成。

<center> <img src="./img/9-2-3-architecture.png"/></center>
<center>图9-2-3. 自动机器学习系统架构</center>

***前沿的Automl优化技术***

探索式训练区别于以往的模型训练在于它的目标不再是将一个单一的模型训练好，而是快速发现模型空间中表现好的模型并将其训练好。这就带来了新的系统优化机会。主要有三类优化，一类是以通用的方式加快多个模型的训练，另一类是加速探索式训练过程，第三类是针对某些探索式训练做定制化的优化。下面依次介绍。

***多模型训练加速***

探索式训练有两个特点：一次可以生成多个模型进行探索，生成的模型之间有很大的相似性。这给跨模型优化带来了很大的优化空间。(i) 由于生成的模型之间相似性很大，这些模型可以共用模型中相同的部分，比如使用相同的数据集，相同的数据预处理逻辑，甚至是相同的子模型。图9-2-4是一个这样的例子。因此，这些相同的计算可以通过去重变成一份。通过对整合后的模型做合理的切分并放置到不同的设备上，可以达到总体更快的训练速度。

<center> <img src="./img/9-2-4-cse.png"/></center>
<center>图9-2-4. 跨模型优化示例</center>

（ii）上面介绍的优化更多的是去重那些没有训练参数的模型部分，对于有训练参数的模型部分，由于每一个模型需要训练自己的参数，因此不能做去重。这时可以做模型之间的融合(fuse)。前面章节介绍过模型优化中的算子融合，即相邻的两个算子可以融合成一个算子从而提升运行效率。而在自动机器学习系统里的融合通常表示不同模型中对应位置的相同算子可以融合在一起，从而达到提升设备利用率(utilization)的效果。这种优化对于小模型的探索式训练非常有效。

***加速探索式训练过程***

探索式训练过程也可以被有效加速，通过对模型训练做合理的资源分配和调度。这里介绍两种优化技术。一是时分复用的模型训练。这种方式会分配少量计算资源给一个新生成的模型，用于初步估计这个模型的效果。如果表现较好则保留继续参与下一轮的时分复用，如果表现不好则直接剔除。这样可以在使用相同量计算资源的情况下，尝试更多的模型，从而快速发现表现好的那些模型。另一种优化技术是通过评估正在训练的模型的表现，动态调整分配给它们的计算资源，表现好的模型会被分配更多资源，而表现较差的模型被分配到的资源会相对较少。在逻辑上和时分复用比较类似，时分复用是进一步精细化资源调度的粒度。这里资源调度上也有不同的种类，比如successive halving，Gandiva。

<!-- ***定制化优化*** -->

探索式训练过程有很多的方法，例如9.1节中介绍的多试验搜索和单发搜索。单发搜索在行为上非常特殊，是将候选的模型结构合并成一个超网络，每一个minibatch只激活该超模型中的一个子模型。这种超模型的高效训练需要有针对性的模型并行（model parallelism）策略。典型的方法有混合并行（mixed parallelism）和NASPipe。

## 9.2.5 自动化机器学习工具概述与实例分析

***自动机器学习工具概述***

目前市面上的自动机器学习工具种类繁多，侧重点各有不同。自动机器学习工具围绕着三个核心能力发展和演进。

  - 模型自动设计与调优的算法。有些自动机器学习工具仅提供一种模型设计和调优算法，如Auto-Sklearn，TPOT，H2O AutoML，AutoKeras。这类工具通常提供十分简洁的用户接口，如`tool.fit`，`tool.predict`。由于不同的机器学习任务（如图像识别，文本分类）通常需要不同的模型设计空间和搜索方式，这类工具会分任务做定制化模型搜索。Auto-Sklearn和TPOT主要针对scikit-learn中的传统机器学习算法，AutoKeras则主要针对深度学习模型。另外一些自动机器学习工具通过模块化设计提供一系列主流的模型搜索算法（如9.1节中介绍的算法），由用户根据自己的需求选择合适的搜索算法应用到自己的任务中，如NNI，Ray。这类工具的定位偏重于辅助模型开发者设计和调优模型。另外，一些工具，如Ray，Weights&Biases，MLflow，在算法上主要支持的是超参数搜索算法。而且Weights&Biases和MLflow虽然有超参数搜索的能力，但是他们在工具的定位上是机器学习训练任务的管理工具。
  - 分布式模型搜索与训练的能力。模型搜索通常需要较多的计算资源。一些自动机器学习工具可以连接到不同类型的计算资源上，比如远程的计算服务器，Kubernetes集群，云计算服务。如Ray和NNI都可以连接不同的计算资源，其中NNI是用统一的接口将不同的计算资源封装起来，令模型搜索无差别的使用不同类型的计算资源（后面会详细介绍）。Ray设计了一种结合了调度能力的远程过程调用（即`ray.remote`），将计算分发到不同的计算节点上。Weights&Biases也具有类似的功能，将试验分发到用户提供的机器上运行。auto-sklearn、AutoKeras没有提供分布式的能力。有些自动机器学习工具与集群管理工具或者云服务紧耦合，如Kubeflow（Kubeflow是在kubernetes上构建的，针对机器学习任务运行和部署的工具）中原生支持的自动机器学习工具Katib。在Katib中，整个超参数搜索的配置，如需要搜索的超参数及取值范围、搜索并行度，直接写到了机器学习训练任务的配置文件中。无论上述哪种方式的分布式能力，只需合理的封装，都可以在云上以SaaS的形式提供自动机器学习能力。
  - 编程接口与用户交互。现有的自动机器学习工具虽然提供的编程接口各不相同，但是总体可以分为两类。一类是用户提供任务数据，工具直接返回搜索到的好的模型，即上述的Auto-Sklearn，TPOT等。另一类是用户需要自己编写或者指定模型，指定搜索空间及合适的搜索算法，来完成搜索过程。用户编写和指定这些内容的方式也有多种，一些工具是通过配置文件描述搜索空间，有些是在Python代码里以dict直接描述，还有些为了描述搜索空间的简便，支持将超参数的可行域直接在模型使用该超参数的对应位置描述出来，如NNI中的ValueChoice。在试验代码的编程方式也有多种，一类是试验代码作为一个独立脚本，通过命令行参数或者工具提供的API和搜索过程交互。另一类是将试验代码写作一个函数，其输入参数是超参数的取值，返回值是该组超参数取值下的表现。前者在试验的隔离性上更优一点，后者在试验代码编写上（特别是较简单的试验代码）更友好一点。用户交互方面有两种模式：命令行和图形化。图形化是机器学习模型开发的有力工具，仅仅针对深度学习模型训练的可视化和管理工具已经涌现出很多，如TensorBoard，Weights&Biases，MLflow。在自动机器学习工具中可视化也是重要的组成部分，每个试验的训练信息，试验之间的对比，搜索过程的演进，搜索出的模型的可视化，以及实验管理等。可以将自动机器学习的可视化视为传统深度学习模型训练可视化的增强。

***NNI***

NNI是轻量级自动机器学习工具其中主要包括超参数搜索、网络结构搜索和模型压缩。这三种类型的任务有一个共同的特点，即不断尝试新的候选模型结构或者配置。每一个候选会被评估。因此，一个自动机器学习工具需要具备的初步功能是面向机器学习的任务分发。NNI在此基础上提供了向不同训练平台分发任务的能力，应用不同搜索算法的能力，以及友好的用户编程和交互接口。

<center> <img src="./img/9-2-5-nni.png"/></center>
<center>图9-2-5. 自动机器学习工具NNI的基础架构</center>

图9-2-5展示了NNI的基础架构。首先，任务分发能力是由图中Training service提供，每一个训练平台都可以通过Training service供自动机器学习任务使用。Tuner/Assesor是搜索算法，NNI提供的编程接口可以支持复杂的搜索算法实现。图左侧是用户编程接口和实验管理接口。

## 小结与讨论

自动机器学习系统和工具是机器学习模型在落地过程中不可或缺的重要组成部分。像机器学习模型的不断进步一样，自动机器学习系统也在不断摸索演进。从模型的训练和调优过程中，提取标准化流程并以系统和工具的形式提高模型开发人员的效率。流程被标准化之后，其中的模块就可以更加通用和高效。随着机器学习模型的日渐成熟，自动机器学习工具也逐渐演进得更加强大。从一个给开发人员的开发工具，到更加端到端模型生成。可以自动化的部分越来越多。另外在模型的整个生命周期上，自动化也越来越多的涉入，比如在模型的部署和服务过程中，也有越来越多的组件被自动化，逐渐演进成整个MLOps。

未来自动的模型设计和调优会更多的涉及到硬件的特性，和硬件上的编译优化联动。。。

自动机器学习系统和工具还有很大的局限性。由于深度学习框架并没有收敛（PyTorch，TensorFlow），给提供一个通用的自动机器学习工具带来很大困难，一些相对高阶的优化方式很难提供稳定鲁棒的支持。另外，端到端的模型自动化生成仍然具有很大挑战，特别是考虑到更加多样的硬件环境。克服这些局限性可以很大程度上帮助机器学习模型的广泛部署。

## 参考文献

1. [Zhang, Quanlu, Zhenhua Han, Fan Yang, Yuge Zhang, Zhe Liu, Mao Yang, and Lidong Zhou. "Retiarii: A Deep Learning {Exploratory-Training} Framework." In 14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20), pp. 919-936. 2020.](https://www.usenix.org/system/files/osdi20-zhang_quanlu.pdf)
