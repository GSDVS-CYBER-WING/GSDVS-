<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 7.4 面向深度学习的集群管理系统

在之前的章节，我们已经介绍经典的调度算法在深度学习作业的集群调度中的原理和应用。但是这些算法本身没有深入的考虑深度学习作业自身的特点，和更加深入的考虑GPU服务器中GPU的拓扑结构。本章将围绕经典且前沿的针对深度学习负载和GPU服务器特点而设计的平台调度算法进行介绍，期望让读者了解新负载和硬件的特点和调度管理需求，并通过更加适合的方式予以解决，并启发新的工作。本章节的很多工作目前没有严格定论，还属于研究的前沿，本章中更多的是总结当前负载，硬件和平台本身的新问题，启发读者未来可以思考新的研究和工程工作。

- [7.4 面向深度学习的集群管理系统](#74-面向深度学习的集群管理系统)
  - [7.4.1 深度学习工作负载的需求](#741-深度学习工作负载的需求)
  - [7.4.2 异构硬件的多样性](#742-异构硬件的多样性)
  - [7.4.3 异构硬件下的调度算法设计](#743-异构硬件下的调度算法设计)
  - [7.4.4 代表性异构集群管理系统](#744-代表性异构集群管理系统)
  - [参考文献](#参考文献)

## 7.4.1 深度学习工作负载的需求

深度学习作业相比传统的大数据作业有一些新的特点和不同。
我们使用的集群管理系统大多数支持的作业是深度学习的训练作业。

- 批量深度学习训练作业特点：深度学习训练作业的一个关键特征是反馈驱动
探索。 由于深度学习实验固有的反复试验方法，用户通常会尝试多个作业配置（多项工作），并使用这些工作的早期反馈来
决定是否优先考虑或杀死其中的某些子集。这种有条件的探索，称为超参数搜索，可以是手动的，也可以是系统自动触发。所以我们经常可以看到集群中有大量类似作业和被提前终止的作业。
- 单个深度学习训练作业特点：
  - 训练时间持续数小时甚至几天。
  - 作业主干部分是迭代的计算，每轮迭代可以切分为小时间窗口的任务。这样让作业本身有机会以更小的粒度触发调度，抢占策略。 
  - 在训练过程中不同的时间点做检查点有不同的数据量，这给做检查点提供了优化机会，如果有检查点的支持，可以让平台或框架本身支持更加激进的调度策略，例如，动态迁移作业，装箱作业到同一块GPU，时分复用等。
  - 资源消耗可预测性，可以通过运行时监控获取。由于其可预测性，让调度器有机会可以根据资源消耗做更加优化的作业放置和装箱。

根据深度学习作业特点和软件栈和硬件栈的底层机制支持，可以设计启发的优化策略，提升资源利用率等指标。

- 装箱 (Packing)：在保证GPU显存约束的情况下，根据浮点运算量，将更多的作业装箱到相同GPU，提升资源利用率。
- 时分复用(Time slicing):利用框架层或底层实现的检查点和恢复机制，多个作业可以通过时分复用，共享单块GPU。
- 迁移 (Migration)：利用框架层或底层实现的检查点和恢复机制，当有空闲资源或奖励资源，动态迁移作业使用免费资源，加速训练，当被抢占迁移作业保证作业之前训练不失效。


## 7.4.2 异构硬件的多样性

深度学习作业使用的服务器一般会挂载多块GPU，而且训练时主要的计算单元是GPU。相比传统的大数据作业和服务器硬件有一些新的特点和不同。多GPU集群运行深度学习问题与挑战：由于多块GPU之间的互联方式多样，造成作业的不同放置方式受到GPU拓扑结构影响，进而影响总线容易产生争用，影响性能。同时，作业本身由于可能共享服务器，数据总线等资源也受到服务器上同时运行作业的干扰。

所以针对硬件特点可以设计启发优化策略：考虑集群和服务器节点的GPU拓扑结构的亲和性(Affinity)调度。这点和传统NUMA架构中考虑CPU亲和性的调度有异曲同工之处。我们可以看到，对系统问题，我们可以从传统的操作系统的经典设计中找到设计原则，对新工作形成指导和借鉴。


## 7.4.3 异构硬件下的调度算法设计

我们接下来以[Gandiva](https://dl.acm.org/doi/10.5555/3291168.3291212)的调度策略为例介绍针对深度学习负载的调度器会考虑哪些影响因素进而设计
相应的策略。

Gandiva设计了两种模式：

一种是反应模式(Reactive Mode)，类似传统调度器事件驱动的设计，根据不同事件和状态（作业到达(arrivals), 离开(departures), 失效(failures)）触发调度策略。
考虑亲和性(affinity)的调度策略：在调度过程中按以下优先级考虑和排序节点进行作业分配，这样能够更多的考虑GPU的亲和性和拓扑结构，让深度学习作业减少数据I/O的瓶颈，提升性能。
其优先考虑的节点优先级为。1. 拥有相同亲和性的节点。2. 还未标注亲和性的节点。3. 有不同亲和性的节点。4. 进行超额订阅(Oversubscription)，在有相同亲和性的节点暂停和恢复其他作业。5. 不满足之前条件，则作业排队等待。

另一种是内省模式(Introspective Mode)，在作业执行后，持续监控并定期优化当前作业的放置 (Placement)，同时通过扩展框架支持细粒度的检查点和恢复功能，对后续策略提供基础原语的支持。通过不断监控作业利用率和节点资源利用率，不断进行作业的，装箱(Packing)，迁移(Migration)，增长收缩(Grow-Shrink)，超额定于和时间切片(Time slicing)，进而提升整体资源利用率，降低作业的完工时间(makespan)。

其他经典针对深度学习的调度器，例如[HiveD](https://dl.acm.org/doi/10.5555/3488766.3488795)等大家可以参考其文献，或使用和测试其已[开源的HiveD调度器](https://github.com/microsoft/hivedscheduler)。

## 7.4.4 代表性异构集群管理系统

本小节我们将介绍代表性的开源和企业内部的大规模异构集群管理系统。基于代表性开源系统，企业可以部署和构建自己的平台，提升资源管理能力，资源利用率和开发效率。基于内部大规模异构集群管理系统所发布的参考文献，企业可以较早的规划和采取最佳实践策略，将未来可预见的问题较早规避，并持续扩容。

- [OpenPAI](https://github.com/microsoft/pai)

OpenPAI是由微软亚洲研究院和微软（亚洲）互联网工程院联合研发的，支持多种深度学习、机器学习及大数据任务，可提供大规模GPU集群调度、集群监控、任务监控、分布式存储等功能，且用户界面友好，易于操作。OpenPAI正在转向更健壮、更强大和更轻量级的架构。OpenPAI 也变得越来越模块化，以便平台可以轻松定制和扩展以满足新的需求。OpenPAI 还提供了许多 AI 用户友好的功能，使最终用户和管理员更容易完成日常的 AI 任务。 

- [Kubeflow](https://www.kubeflow.org/)

Kubeflow是由Google开源的平台项目，该项目致力于使机器学习工作流在 Kubernetes上的部署变得简单、便携和可扩展。Kubeflow的设计目标不是重新创建其他服务，而是提供一种直接的方法，将用于机器学习和深度学习的同类最佳开源系统部署到不同的基础设施。无论用户在何处运行Kubernetes，都可以运行Kubeflow。 

- [Philly](https://dl.acm.org/doi/10.5555/3358807.3358888)

Philly是微软内部使用的大规模AI训练平台，Philly 旨在支持执行有监督式机器学习的训练工作负载。 这包括培训来自开发产品的生产团队的工作，这些产品使用用于图像分类、语音识别等的模型。有相关研究工作对Philly上的[资源分配，深度学习作业性能特点](https://dl.acm.org/doi/10.5555/3358807.3358888)和[深度学习程序Bug](https://dl.acm.org/doi/10.1145/3377811.3380362)进行研究，从中我们可以观察和了解大规模生产环境中作业资源争用，资源利用率，调度策略设计和程序Bug等问题及启发相关新的研究工作。  

## 参考文献
- https://github.com/microsoft/pai
- https://www.kubeflow.org/
- [Myeongjae Jeon, Shivaram Venkataraman, Amar Phanishayee, unjie Qian, Wencong Xiao, and Fan Yang. 2019. Analysis of large-scale multi-tenant GPU clusters for DNN training workloads. In Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC '19). USENIX Association, USA, 947–960.](https://dl.acm.org/doi/10.5555/3358807.3358888)
- [Ru Zhang, Wencong Xiao, Hongyu Zhang, Yu Liu, Haoxiang Lin, and Mao Yang. 2020. An empirical study on program failures of deep learning jobs. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (ICSE '20). Association for Computing Machinery, New York, NY, USA, 1159–1170. DOI:https://doi.org/10.1145/3377811.3380362](https://dl.acm.org/doi/10.1145/3377811.3380362)
- [Wencong Xiao, Romil Bhardwaj, Ramachandran Ramjee, Muthian Sivathanu, Nipun Kwatra, Zhenhua Han, Pratyush Patel, Xuan Peng, Hanyu Zhao, Quanlu Zhang, Fan Yang, and Lidong Zhou. 2018. Gandiva: introspective cluster scheduling for deep learning. In Proceedings of the 13th USENIX conference on Operating Systems Design and Implementation (OSDI'18). USENIX Association, USA, 595–610.](https://dl.acm.org/doi/10.5555/3291168.3291212)
- [Hanyu Zhao, Zhenhua Han, Zhi Yang, Quanlu Zhang, Fan Yang, Lidong Zhou, Mao Yang, Francis C.M. Lau, Yuqi Wang, Yifan Xiong, and Bin Wang. 2020. HiveD: sharing a GPU cluster for deep learning with guarantees. Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation. Article 29, 515–532.](https://dl.acm.org/doi/10.5555/3488766.3488795)
- https://www.msra.cn/zh-cn/news/features/openpai
